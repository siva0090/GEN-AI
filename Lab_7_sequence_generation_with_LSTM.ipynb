{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3jhE10MYsuc",
        "outputId": "4e8367ec-4c39-43cf-99bc-ebf6928028ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "600901/600901 [==============================] - 0s 1us/step\n",
            "corpus length: 600893\n",
            "total chars: 57\n",
            "nb sequences: 200285\n",
            "Vectorization...\n",
            "Build model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1562/1565 [============================>.] - ETA: 0s - loss: 2.5694\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"is own thoughts as if they came from the\"\n",
            "is own thoughts as if they came from the prelis th\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"is own thoughts as if they came from the\"\n",
            "is own thoughts as if they came from the the pored\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"is own thoughts as if they came from the\"\n",
            "is own thoughts as if they came from the\n",
            "des in wa\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"is own thoughts as if they came from the\"\n",
            "is own thoughts as if they came from the\n",
            "masstar, \n",
            "1565/1565 [==============================] - 15s 7ms/step - loss: 2.5693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cd83c145a80>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(10):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "          callbacks=[print_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPP6jTjpbmK1",
        "outputId": "1f506dcb-587b-4bd7-f373-4a1d930eefb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.0.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.13)\n",
            "Installing collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.13 jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Using 1D Convs for generate text from rom Nietzsche's and Shakepear's\n",
        "writings\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import get_file\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "\n",
        "# 2nd Dataset : Combined works of Shakespeare\n",
        "# path = get_file('shakespeare_input.txt', origin='https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt')\n",
        "\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "# print(x.shape[0])\n",
        "# print(x.shape[1])\n",
        "# print(x.shape[2])\n",
        "\n",
        "\n",
        "def build_model(maxlen, chars):\n",
        "\n",
        "    print('Build model...')\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(128, 5, padding='same', activation='relu', input_shape=(maxlen, len(chars))))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "    # model 2 : VGG net like architecture, 5 layers\n",
        "#     model.add(Conv1D(64, 3, activation='relu',input_shape=(maxlen, len(chars))))\n",
        "#     model.add(Conv1D(64, 3, activation='relu'))\n",
        "#     model.add(MaxPooling1D(pool_size=2))\n",
        "#     model.add(Conv1D(128, 3, activation='relu'))\n",
        "#     model.add(Conv1D(128, 3, activation='relu'))\n",
        "#     model.add(MaxPooling1D(pool_size=2))\n",
        "#     model.add(Flatten())\n",
        "#     model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "    #model 3: adapted from https://keras.io/getting-started/sequential-model-guide/\n",
        "#     model.add(Conv1D(64, 3, activation='relu',input_shape=(maxlen, len(chars))))\n",
        "#     model.add(Conv1D(64, 3, activation='relu'))\n",
        "#     model.add(MaxPooling1D(pool_size=3))\n",
        "#     model.add(Conv1D(128, 3, activation='relu'))\n",
        "#     model.add(Conv1D(128, 3, activation='relu'))\n",
        "#     model.add(MaxPooling1D(pool_size=3))\n",
        "#     model.add(GlobalAveragePooling1D())\n",
        "#     model.add(Dropout(0.5))\n",
        "# #     model.add(Flatten())\n",
        "#     model.add(Dense(len(chars), activation='sigmoid'))\n",
        "\n",
        "\n",
        "    optimizer = RMSprop(lr=0.01)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return model\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(10):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "    model = build_model(maxlen, chars)\n",
        "\n",
        "    import ipdb;\n",
        "\n",
        "    model.fit(\n",
        "        x,\n",
        "        y,\n",
        "        batch_size=128,\n",
        "        epochs=1,\n",
        "        callbacks=[print_callback]\n",
        "    )\n",
        "    ipdb.set_trace()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afQMpx7vYtcg",
        "outputId": "85a595d4-db50-4963-f540-c3e4a781ace7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 600893\n",
            "total chars: 57\n",
            "nb sequences: 200285\n",
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "1565/1565 [==============================] - ETA: 0s - loss: 2.3276\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"her \"categorical,\"\n",
            "as old kant wished (c\"\n",
            "her \"categorical,\"\n",
            "as old kant wished (conter and \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"her \"categorical,\"\n",
            "as old kant wished (c\"\n",
            "her \"categorical,\"\n",
            "as old kant wished (cous eat in\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"her \"categorical,\"\n",
            "as old kant wished (c\"\n",
            "her \"categorical,\"\n",
            "as old kant wished (cordean and\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"her \"categorical,\"\n",
            "as old kant wished (c\"\n",
            "her \"categorical,\"\n",
            "as old kant wished (cempresammy\n",
            "1565/1565 [==============================] - 11s 6ms/step - loss: 2.3276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/bdb.py\", line 336, in set_trace\n",
            "    sys.settrace(self.trace_dispatch)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Return--\n",
            "None\n",
            "> \u001b[0;32m<ipython-input-3-0a5028eb9ca3>\u001b[0m(147)\u001b[0;36m<cell line: 133>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    145 \u001b[0;31m        \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    146 \u001b[0;31m    )\n",
            "\u001b[0m\u001b[0;32m--> 147 \u001b[0;31m    \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}